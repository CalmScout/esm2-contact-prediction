{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Serving for ESM2 Contact Prediction\n",
    "\n",
    "This notebook demonstrates how to serve the trained ESM2 contact prediction model on new PDB files. We'll cover the complete pipeline from PDB file input to contact prediction output, including:\n",
    "\n",
    "- Loading trained models using the serving infrastructure\n",
    "- Processing PDB files and extracting protein chains\n",
    "- Generating ESM2 embeddings for contact prediction\n",
    "- Making predictions and analyzing results\n",
    "- Batch processing multiple PDB files\n",
    "- REST API serving (optional)\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. **Model Loading**: How to load trained models for inference\n",
    "2. **PDB Processing**: Extract protein sequences and structural information\n",
    "3. **Feature Generation**: Create ESM2 embeddings from protein sequences\n",
    "4. **Contact Prediction**: Use the model to predict protein contact maps\n",
    "5. **Result Analysis**: Visualize and evaluate predictions\n",
    "6. **Production Serving**: Deploy models via REST API\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Trained model checkpoint (`.pth` file) or MLflow model URI\n",
    "- PDB files for prediction\n",
    "- Required dependencies installed (`esm`, `torch`, `mlflow`, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports loaded successfully!\n",
      "   PyTorch version: 2.9.0+cu128\n",
      "   CUDA available: True\n",
      "   GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# PyTorch and ML\n",
    "import torch\n",
    "import esm\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "\n",
    "# Progress tracking\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Project modules\n",
    "sys.path.append('..')\n",
    "from src.esm2_contact.serving import ContactPredictor, create_pyfunc_model, log_model_to_mlflow\n",
    "from src.esm2_contact.dataset.processing import extract_chains_from_pdb, compute_contact_map, load_amino_acid_mapping\n",
    "from src.notebook_utils.esm2_embeddings import compute_esm2_embeddings_batch\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ All imports loaded successfully!\")\n",
    "print(f\"   PyTorch version: {torch.__version__}\")\n",
    "print(f\"   CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - Update these paths as needed\n",
    "CONFIG = {\n",
    "    # Model paths\n",
    "    'model_checkpoint': '../experiments/full_dataset_training/model.pth',  # Update with your model path\n",
    "    'mlflow_model_uri': 'runs:/411149998746302666/m-af9291099ab9441fbf4cb47431763fe7',  # MLflow model URI\n",
    "    \n",
    "    # Data paths\n",
    "    'pdb_dir': '../data/train',  # Directory containing PDB files\n",
    "    'output_dir': '../predictions',  # Directory to save predictions\n",
    "    'test_pdb': '../data/train/4H2C.pdb',  # Example PDB file\n",
    "    \n",
    "    # Model configuration\n",
    "    'prediction_threshold': 0.5,  # Threshold for binary contact prediction\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',  # Device for inference\n",
    "    'esm_model': 'esm2_t33_650M_UR50D',  # ESM2 model variant for embeddings\n",
    "    'batch_size': 1,  # Batch size for ESM2 embedding computation\n",
    "    'esm_layer': 33,  # ESM2 layer to extract embeddings from\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load Model from Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Setting up model loading...\n",
      "‚úÖ Configuration loaded from: /home/calmscout/Projects/PythonProjects/esm2-contact-prediction/experiments/full_dataset_training/config.json\n",
      "   Architecture: CNN (68‚Üí32 channels)\n",
      "‚úÖ Model file found: /home/calmscout/Projects/PythonProjects/esm2-contact-prediction/experiments/full_dataset_training/model.pth\n",
      "üìÇ Loading model from: /home/calmscout/Projects/PythonProjects/esm2-contact-prediction/experiments/full_dataset_training/model.pth\n",
      "üîß Model config: 68‚Üí32 channels\n",
      "‚úÖ Model state dict loaded from checkpoint\n",
      "‚úÖ Model loaded successfully!\n",
      "   Model type: BinaryContactCNN\n",
      "   Parameters: 380,033\n",
      "   Input channels: 68\n",
      "   Base channels: 32\n",
      "   Device: cuda\n",
      "\n",
      "üß™ Testing model with dummy input...\n",
      "   Input shape: torch.Size([1, 68, 64, 64])\n",
      "   Output shape: torch.Size([1, 64, 64])\n",
      "   Output type: <class 'torch.Tensor'>\n",
      "   Output range: [-9.5421, 6.7355]\n",
      "‚úÖ Model inference test successful!\n",
      "\n",
      "üéâ Model loading completed successfully!\n",
      "   Model type: BinaryContactCNN\n"
     ]
    }
   ],
   "source": [
    "# Load model using the successful approach from results analysis\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Resolve paths from notebook location (notebooks/ -> project root)\n",
    "notebook_dir = Path().absolute()\n",
    "project_root = notebook_dir.parent\n",
    "LOCAL_EXPERIMENT_DIR = project_root / \"experiments/full_dataset_training\"\n",
    "\n",
    "# Load experiment configuration\n",
    "config = None\n",
    "model_path = None\n",
    "pytorch_model = None\n",
    "\n",
    "print(\"üîÑ Setting up model loading...\")\n",
    "\n",
    "# Load configuration from local experiment\n",
    "if LOCAL_EXPERIMENT_DIR.exists():\n",
    "    config_file = LOCAL_EXPERIMENT_DIR / \"config.json\"\n",
    "    model_file = LOCAL_EXPERIMENT_DIR / \"model.pth\"\n",
    "    \n",
    "    if config_file.exists():\n",
    "        import json\n",
    "        with open(config_file, \"r\") as f:\n",
    "            config = json.load(f)\n",
    "        print(f\"‚úÖ Configuration loaded from: {config_file}\")\n",
    "        print(f\"   Architecture: CNN ({config['in_channels']}‚Üí{config['base_channels']} channels)\")\n",
    "    \n",
    "    if model_file.exists():\n",
    "        model_path = str(model_file)\n",
    "        print(f\"‚úÖ Model file found: {model_path}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Model file not found: {model_file}\")\n",
    "else:\n",
    "    print(f\"‚ùå Experiment directory not found: {LOCAL_EXPERIMENT_DIR}\")\n",
    "\n",
    "# Load PyTorch model using the proven approach\n",
    "if config and model_path:\n",
    "    try:\n",
    "        # Ensure the project root is in the Python path\n",
    "        if str(project_root) not in sys.path:\n",
    "            sys.path.insert(0, str(project_root))\n",
    "        \n",
    "        # Import the model class\n",
    "        from src.esm2_contact.training.model import BinaryContactCNN\n",
    "        \n",
    "        print(f\"üìÇ Loading model from: {model_path}\")\n",
    "        print(f\"üîß Model config: {config['in_channels']}‚Üí{config['base_channels']} channels\")\n",
    "        \n",
    "        # Create model instance with the same configuration as training\n",
    "        model = BinaryContactCNN(\n",
    "            in_channels=config['in_channels'],\n",
    "            base_channels=config['base_channels'],\n",
    "            dropout_rate=config['dropout_rate']\n",
    "        )\n",
    "        \n",
    "        # Load trained weights with proper checkpoint handling\n",
    "        import torch\n",
    "        checkpoint = torch.load(model_path, map_location=CONFIG['device'])\n",
    "        \n",
    "        if 'model_state_dict' in checkpoint:\n",
    "            # Extract the actual state dict from the checkpoint\n",
    "            state_dict = checkpoint['model_state_dict']\n",
    "            model.load_state_dict(state_dict)\n",
    "            print(f\"‚úÖ Model state dict loaded from checkpoint\")\n",
    "        else:\n",
    "            # Fallback: try loading the checkpoint directly\n",
    "            model.load_state_dict(checkpoint)\n",
    "            print(f\"‚úÖ Model loaded directly from checkpoint\")\n",
    "        \n",
    "        model.eval()  # Set to evaluation mode\n",
    "        model.to(CONFIG['device'])  # Move to target device\n",
    "        \n",
    "        print(f\"‚úÖ Model loaded successfully!\")\n",
    "        print(f\"   Model type: {type(model).__name__}\")\n",
    "        print(f\"   Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "        print(f\"   Input channels: {config['in_channels']}\")\n",
    "        print(f\"   Base channels: {config['base_channels']}\")\n",
    "        print(f\"   Device: {CONFIG['device']}\")\n",
    "        \n",
    "        # Store model for later use\n",
    "        pytorch_model = model\n",
    "        \n",
    "        # Test model with dummy data to verify functionality\n",
    "        print(f\"\\nüß™ Testing model with dummy input...\")\n",
    "        dummy_input = torch.randn(1, config['in_channels'], 64, 64).to(CONFIG['device'])\n",
    "        with torch.no_grad():\n",
    "            dummy_output = model(dummy_input)\n",
    "            print(f\"   Input shape: {dummy_input.shape}\")\n",
    "            print(f\"   Output shape: {dummy_output.shape}\")\n",
    "            print(f\"   Output type: {type(dummy_output)}\")\n",
    "            print(f\"   Output range: [{dummy_output.min():.4f}, {dummy_output.max():.4f}]\")\n",
    "        \n",
    "        print(f\"‚úÖ Model inference test successful!\")\n",
    "        \n",
    "    except ImportError as ie:\n",
    "        print(f\"‚ùå Import error: {ie}\")\n",
    "        print(f\"   Could not import BinaryContactCNN from src.esm2_contact.training.model\")\n",
    "        pytorch_model = None\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load PyTorch model: {e}\")\n",
    "        print(f\"   Error type: {type(e).__name__}\")\n",
    "        pytorch_model = None\n",
    "\n",
    "# Fallback to ContactPredictor if PyTorch loading fails\n",
    "if pytorch_model is None:\n",
    "    print(f\"\\nüîÑ Attempting to load using ContactPredictor...\")\n",
    "    model_path = Path(CONFIG['model_checkpoint'])\n",
    "    \n",
    "    if model_path.exists():\n",
    "        try:\n",
    "            from src.esm2_contact.serving import ContactPredictor\n",
    "            \n",
    "            predictor = ContactPredictor(\n",
    "                model_path=CONFIG['model_checkpoint'],\n",
    "                threshold=CONFIG['prediction_threshold'],\n",
    "                device=CONFIG['device']\n",
    "            )\n",
    "            \n",
    "            print(f\"‚úÖ ContactPredictor loaded successfully!\")\n",
    "            pytorch_model = predictor\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to load ContactPredictor: {e}\")\n",
    "            pytorch_model = None\n",
    "\n",
    "# Final fallback to MLflow\n",
    "if pytorch_model is None and CONFIG['mlflow_model_uri']:\n",
    "    print(f\"\\nüîÑ Attempting to load MLflow model...\")\n",
    "    try:\n",
    "        mlflow_model = mlflow.pyfunc.load_model(CONFIG['mlflow_model_uri'])\n",
    "        \n",
    "        # Test with dummy input\n",
    "        dummy_input = np.random.randn(1, config['in_channels'] if config else 68, 64, 64).astype(np.float32)\n",
    "        test_result = mlflow_model.predict(None, dummy_input)\n",
    "        \n",
    "        print(f\"‚úÖ MLflow model loaded successfully!\")\n",
    "        pytorch_model = mlflow_model\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load MLflow model: {e}\")\n",
    "        pytorch_model = None\n",
    "\n",
    "# Final status\n",
    "if pytorch_model is not None:\n",
    "    print(f\"\\nüéâ Model loading completed successfully!\")\n",
    "    print(f\"   Model type: {type(pytorch_model).__name__}\")\n",
    "    predictor = pytorch_model\n",
    "else:\n",
    "    print(f\"\\n‚ùå No model could be loaded. Please check model paths and dependencies.\")\n",
    "    print(f\"   Model checkpoint: {CONFIG['model_checkpoint']}\")\n",
    "    print(f\"   MLflow URI: {CONFIG['mlflow_model_uri']}\")\n",
    "    predictor = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Model Loading Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Current model status:\n",
      "   Model type: BinaryContactCNN\n",
      "   Model loaded: True\n",
      "   Device: cuda\n",
      "   Ready for inference: ‚úÖ\n"
     ]
    }
   ],
   "source": [
    "# Model loading was completed successfully in cell 6\n",
    "print(f\"‚úÖ Current model status:\")\n",
    "print(f\"   Model type: {type(predictor).__name__}\")\n",
    "print(f\"   Model loaded: {predictor is not None}\")\n",
    "\n",
    "if predictor is not None:\n",
    "    print(f\"   Device: {CONFIG['device']}\")\n",
    "    print(f\"   Ready for inference: ‚úÖ\")\n",
    "else:\n",
    "    print(f\"   Ready for inference: ‚ùå\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. PDB File Processing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Load Amino Acid Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 20 amino acid mappings\n",
      "   Examples: [('ALA', 'A'), ('ARG', 'R'), ('ASN', 'N'), ('ASP', 'D'), ('CYS', 'C')]\n"
     ]
    }
   ],
   "source": [
    "# Load amino acid 3-letter to 1-letter mapping\n",
    "aa_mapping_file = '../amino_acid_three_to_one.json'\n",
    "aa_three_to_one = load_amino_acid_mapping(aa_mapping_file)\n",
    "print(f\"‚úÖ Loaded {len(aa_three_to_one)} amino acid mappings\")\n",
    "print(f\"   Examples: {list(aa_three_to_one.items())[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Process Example PDB File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Using example PDB file: ../data/train/4H2C.pdb\n",
      "üîÑ Extracting protein chains...\n",
      "‚úÖ Found 1 chains:\n",
      "   Chain A: 555 residues\n",
      "   Sequence: GAPWWKSAVFYQVYPRSFKDTNGDGIGDFKGLTEKLDYLKGLGIDAIWIN...\n"
     ]
    }
   ],
   "source": [
    "# Find an example PDB file\n",
    "def find_example_pdb():\n",
    "    \"\"\"Find an example PDB file for demonstration.\"\"\"\n",
    "    # Try to configured test PDB first\n",
    "    if CONFIG['test_pdb'] and Path(CONFIG['test_pdb']).exists():\n",
    "        return Path(CONFIG['test_pdb'])\n",
    "    \n",
    "    # Look in PDB directory\n",
    "    pdb_dir = Path(CONFIG['pdb_dir'])\n",
    "    if pdb_dir.exists():\n",
    "        pdb_files = list(pdb_dir.glob('*.pdb'))\n",
    "        if pdb_files:\n",
    "            return pdb_files[0]\n",
    "    \n",
    "    return None\n",
    "\n",
    "example_pdb = find_example_pdb()\n",
    "\n",
    "if example_pdb:\n",
    "    print(f\"üìÑ Using example PDB file: {example_pdb}\")\n",
    "    \n",
    "    # Extract chains from PDB\n",
    "    print(\"üîÑ Extracting protein chains...\")\n",
    "    chains_data = extract_chains_from_pdb(example_pdb, aa_three_to_one)\n",
    "    \n",
    "    print(f\"‚úÖ Found {len(chains_data)} chains:\")\n",
    "    for chain_id, data in chains_data.items():\n",
    "        print(f\"   Chain {chain_id}: {data['length']} residues\")\n",
    "        print(f\"   Sequence: {data['sequence'][:50]}{'...' if len(data['sequence']) > 50 else ''}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå No PDB files found. Please update CONFIG['pdb_dir'] or CONFIG['test_pdb']\")\n",
    "    # Exit gracefully if no data available\n",
    "    raise FileNotFoundError(\"No PDB files available for processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Generate ESM2 Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading ESM2 model: esm2_t33_650M_UR50D\n",
      "‚úÖ ESM2 model loaded on cuda\n",
      "   Model parameters: 651,043,254\n",
      "   Number of layers: 33\n"
     ]
    }
   ],
   "source": [
    "# Load ESM2 model for embeddings\n",
    "print(f\"üîÑ Loading ESM2 model: {CONFIG['esm_model']}\")\n",
    "esm_model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "esm_model.eval()\n",
    "esm_model.to(CONFIG['device'])\n",
    "\n",
    "print(f\"‚úÖ ESM2 model loaded on {CONFIG['device']}\")\n",
    "print(f\"   Model parameters: {sum(p.numel() for p in esm_model.parameters()):,}\")\n",
    "print(f\"   Number of layers: {esm_model.num_layers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Processing 1 sequences for ESM2 embeddings\n",
      "   4H2C_A: 555 residues\n",
      "\n",
      "üß† Computing ESM2 embeddings...\n",
      "üî¢ Computing embeddings from layer 33\n",
      "üì¶ Batch size: 1\n",
      "üñ•Ô∏è  Device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aa6f161b9ab4f1c916a4bbdbe20d6fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing embeddings:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Computed embeddings for 1 sequences\n",
      "‚úÖ ESM2 embeddings computed in 0.33s\n",
      "   4H2C_A: (555, 1280)\n"
     ]
    }
   ],
   "source": [
    "# Prepare sequences for ESM2\n",
    "sequences_list = []\n",
    "for chain_id, data in chains_data.items():\n",
    "    sequences_list.append((f\"{example_pdb.stem}_{chain_id}\" if example_pdb else f\"synthetic_{chain_id}\", \n",
    "                          data['sequence']))\n",
    "\n",
    "print(f\"üìä Processing {len(sequences_list)} sequences for ESM2 embeddings\")\n",
    "for name, seq in sequences_list:\n",
    "    print(f\"   {name}: {len(seq)} residues\")\n",
    "\n",
    "# Compute ESM2 embeddings\n",
    "print(\"\\nüß† Computing ESM2 embeddings...\")\n",
    "start_time = time.time()\n",
    "\n",
    "embeddings_dict = compute_esm2_embeddings_batch(\n",
    "    model=esm_model,\n",
    "    batch_converter=batch_converter,\n",
    "    sequences_list=sequences_list,\n",
    "    device=CONFIG['device'],\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    layer=CONFIG['esm_layer'],\n",
    "    return_contacts=False,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "embedding_time = time.time() - start_time\n",
    "print(f\"‚úÖ ESM2 embeddings computed in {embedding_time:.2f}s\")\n",
    "\n",
    "# Display embedding information\n",
    "for identifier, data in embeddings_dict.items():\n",
    "    embedding = data['embedding']\n",
    "    print(f\"   {identifier}: {embedding.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Create Contact Prediction Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Creating contact prediction features...\n",
      "   Processing 4H2C_A:\n",
      "     ESM2 embedding shape: (555, 1280)\n",
      "     Template channels shape: (4, 555, 555)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (555,64) into shape (555,555)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 98\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m     Template channels shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtemplate_channels.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# Assemble 68-channel tensor\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m feature_map = \u001b[43massemble_68_channel_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemplate_channels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m     Final feature map shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeature_map.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    101\u001b[39m feature_maps.append(feature_map)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 78\u001b[39m, in \u001b[36massemble_68_channel_features\u001b[39m\u001b[34m(esm2_embedding, template_channels)\u001b[39m\n\u001b[32m     74\u001b[39m esm2_64_channels = esm2_embedding[:, :\u001b[32m64\u001b[39m]  \u001b[38;5;66;03m# Shape: (L, 64)\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m64\u001b[39m):\n\u001b[32m     77\u001b[39m     \u001b[38;5;66;03m# Tile each ESM2 dimension across the sequence to create 2D map\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[43mtensor\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m = np.tile(esm2_64_channels[i:i+\u001b[32m1\u001b[39m, :], (L, \u001b[32m1\u001b[39m))\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "\u001b[31mValueError\u001b[39m: could not broadcast input array from shape (555,64) into shape (555,555)"
     ]
    }
   ],
   "source": [
    "# Create feature maps from embeddings for contact prediction (matching training pipeline)\n",
    "print(\"üîÑ Creating contact prediction features...\")\n",
    "\n",
    "def create_template_channels(sequence_length: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create 4 template channels with sequence-based patterns.\n",
    "    \n",
    "    Args:\n",
    "        sequence_length: Length of the protein sequence\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Template channels of shape (4, L, L)\n",
    "    \"\"\"\n",
    "    L = sequence_length\n",
    "    template_channels = np.zeros((4, L, L), dtype=np.float32)\n",
    "    \n",
    "    # Channel 0: Sequential proximity pattern\n",
    "    for i in range(L):\n",
    "        for j in range(L):\n",
    "            if abs(i - j) <= 2:\n",
    "                template_channels[0, i, j] = 0.8\n",
    "    \n",
    "    # Channel 1: Distance-based exponential decay pattern\n",
    "    for i in range(L):\n",
    "        for j in range(L):\n",
    "            dist = abs(i - j)\n",
    "            if dist <= 8:\n",
    "                template_channels[1, i, j] = np.exp(-dist / 4.0)\n",
    "    \n",
    "    # Channel 2: Helical propensity pattern with periodicity\n",
    "    for i in range(L):\n",
    "        for j in range(L):\n",
    "            if i != j:\n",
    "                dist = abs(i - j)\n",
    "                # Helical periodicity pattern\n",
    "                if 3 <= dist <= 5:\n",
    "                    template_channels[2, i, j] = 0.3\n",
    "                elif dist >= 15:\n",
    "                    template_channels[2, i, j] = 0.1\n",
    "    \n",
    "    # Channel 3: Long-range coevolution pattern\n",
    "    for i in range(L):\n",
    "        for j in range(L):\n",
    "            if i != j:\n",
    "                dist = abs(i - j)\n",
    "                if dist > 12 and dist < 50:\n",
    "                    template_channels[3, i, j] = 0.2 * (1 - dist / 50)\n",
    "    \n",
    "    # Set diagonal to 1.0 for all template channels\n",
    "    for i in range(4):\n",
    "        np.fill_diagonal(template_channels[i], 1.0)\n",
    "    \n",
    "    return template_channels\n",
    "\n",
    "def assemble_68_channel_features(esm2_embedding: np.ndarray, template_channels: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Assemble 68-channel tensor following the training pipeline approach.\n",
    "    \n",
    "    Args:\n",
    "        esm2_embedding: ESM2 embeddings of shape (L, 1280)\n",
    "        template_channels: Template channels of shape (4, L, L)\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: 68-channel tensor of shape (68, L, L)\n",
    "    \"\"\"\n",
    "    L = esm2_embedding.shape[0]\n",
    "    channels = 68\n",
    "    tensor = np.zeros((channels, L, L), dtype=np.float32)\n",
    "    \n",
    "    # Channels 0-3: Template channels\n",
    "    tensor[0:4] = template_channels\n",
    "    \n",
    "    # Channels 4-67: ESM2 channels (use first 64 dimensions)\n",
    "    esm2_64_channels = esm2_embedding[:, :64]  # Shape: (L, 64)\n",
    "    \n",
    "    for i in range(64):\n",
    "        # Tile each ESM2 dimension across the sequence to create 2D map\n",
    "        tensor[4 + i] = np.tile(esm2_64_channels[i:i+1, :], (L, 1))\n",
    "    \n",
    "    return tensor\n",
    "\n",
    "# Process each chain\n",
    "feature_maps = []\n",
    "chain_info = []\n",
    "\n",
    "for i, (identifier, data) in enumerate(embeddings_dict.items()):\n",
    "    embedding = data['embedding']  # Shape: (L, 1280)\n",
    "    chain_data = chains_data[list(chains_data.keys())[i]]\n",
    "    \n",
    "    print(f\"   Processing {identifier}:\")\n",
    "    print(f\"     ESM2 embedding shape: {embedding.shape}\")\n",
    "    \n",
    "    # Create template channels\n",
    "    template_channels = create_template_channels(embedding.shape[0])\n",
    "    print(f\"     Template channels shape: {template_channels.shape}\")\n",
    "    \n",
    "    # Assemble 68-channel tensor\n",
    "    feature_map = assemble_68_channel_features(embedding, template_channels)\n",
    "    print(f\"     Final feature map shape: {feature_map.shape}\")\n",
    "    \n",
    "    feature_maps.append(feature_map)\n",
    "    chain_info.append({\n",
    "        'identifier': identifier,\n",
    "        'sequence_length': embedding.shape[0],\n",
    "        'original_sequence': chain_data['sequence']\n",
    "    })\n",
    "\n",
    "# Convert to numpy array for model input\n",
    "features_array = np.stack(feature_maps)\n",
    "print(f\"\\n‚úÖ 68-channel feature maps created: {features_array.shape}\")\n",
    "\n",
    "# Resize to match model input size (64x64) if needed\n",
    "target_size = 64\n",
    "processed_features = []\n",
    "\n",
    "for feature_map in feature_maps:\n",
    "    channels, h, w = feature_map.shape\n",
    "    \n",
    "    if h == target_size and w == target_size:\n",
    "        processed_features.append(feature_map)\n",
    "    else:\n",
    "        # Resize to target size\n",
    "        if h > target_size or w > target_size:\n",
    "            # Take center crop\n",
    "            start_h = max(0, (h - target_size) // 2)\n",
    "            start_w = max(0, (w - target_size) // 2)\n",
    "            resized_map = feature_map[:, start_h:start_h+target_size, start_w:start_w+target_size]\n",
    "        else:\n",
    "            # Pad with zeros\n",
    "            padded_map = np.zeros((channels, target_size, target_size), dtype=np.float32)\n",
    "            padded_map[:, :h, :w] = feature_map\n",
    "            resized_map = padded_map\n",
    "        \n",
    "        processed_features.append(resized_map)\n",
    "        print(f\"   Resized from {feature_map.shape} to {resized_map.shape}\")\n",
    "\n",
    "features_array = np.stack(processed_features)\n",
    "print(f\"‚úÖ Final features ready for model input: {features_array.shape}\")\n",
    "print(f\"   Expected by model: (batch, 68, 64, 64)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Contact Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for direct PyTorch model inference\n",
    "def direct_model_inference(model, features_array, config):\n",
    "    \"\"\"\n",
    "    Handle inference for direct PyTorch models (BinaryContactCNN).\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model (BinaryContactCNN)\n",
    "        features_array: numpy array of shape (batch, channels, height, width)\n",
    "        config: configuration dictionary\n",
    "        \n",
    "    Returns:\n",
    "        dict: Predictions in the same format as ContactPredictor\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    \n",
    "    # Convert numpy array to torch tensor\n",
    "    if isinstance(features_array, np.ndarray):\n",
    "        features_tensor = torch.from_numpy(features_array).float().to(config['device'])\n",
    "    else:\n",
    "        features_tensor = features_array.to(config['device'])\n",
    "    \n",
    "    # Ensure correct input shape (batch, channels, height, width)\n",
    "    if features_tensor.dim() == 4:\n",
    "        # Expected shape: (batch_size, channels, height, width)\n",
    "        pass\n",
    "    elif features_tensor.dim() == 3:\n",
    "        # Add batch dimension if missing\n",
    "        features_tensor = features_tensor.unsqueeze(0)\n",
    "    \n",
    "    # Run inference\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        raw_outputs = model(features_tensor)  # Shape: (batch, height, width)\n",
    "        \n",
    "        # Apply sigmoid to get probabilities\n",
    "        probabilities = torch.sigmoid(raw_outputs)\n",
    "        \n",
    "        # Apply threshold to get binary predictions\n",
    "        threshold = config['prediction_threshold']\n",
    "        binary_predictions = (probabilities >= threshold).float()\n",
    "        \n",
    "        # Calculate confidence scores (distance from threshold)\n",
    "        confidence_scores = torch.abs(probabilities - 0.5) * 2  # Maps to [0, 1]\n",
    "    \n",
    "    # Convert back to numpy and format results\n",
    "    batch_size = features_tensor.shape[0]\n",
    "    \n",
    "    results = {\n",
    "        'batch_size': batch_size,\n",
    "        'threshold': threshold,\n",
    "        'predictions': [],\n",
    "        'probabilities': [],\n",
    "        'confidence_scores': []\n",
    "    }\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        results['predictions'].append(binary_predictions[i].cpu().numpy())\n",
    "        results['probabilities'].append(probabilities[i].cpu().numpy())\n",
    "        results['confidence_scores'].append(confidence_scores[i].cpu().numpy())\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if predictor is not None:\n",
    "    print(\"üîÆ Making contact predictions...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Make predictions based on model type\n",
    "    if hasattr(predictor, '_predict_batch'):\n",
    "        # ContactPredictor class\n",
    "        predictions = predictor._predict_batch(features_array)\n",
    "    elif hasattr(predictor, 'forward'):\n",
    "        # Direct PyTorch model (BinaryContactCNN)\n",
    "        predictions = direct_model_inference(predictor, features_array, CONFIG)\n",
    "    elif hasattr(predictor, 'predict'):\n",
    "        # MLflow pyfunc model\n",
    "        predictions = predictor.predict(None, features_array)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {type(predictor)}\")\n",
    "    \n",
    "    prediction_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"‚úÖ Predictions completed in {prediction_time:.4f}s\")\n",
    "    print(f\"   Batch size: {predictions['batch_size']}\")\n",
    "    print(f\"   Prediction shapes:\")\n",
    "    \n",
    "    for i, (chain_info_item, pred_shape) in enumerate(zip(chain_info, predictions['predictions'])):\n",
    "        print(f\"     {chain_info_item['identifier']}: {np.array(pred_shape).shape}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No model loaded. Please load a model first.\")\n",
    "    raise RuntimeError(\"Model loading failed - cannot proceed with predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Process and Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process predictions and create results summary\n",
    "results_summary = []\n",
    "\n",
    "for i, chain_info_item in enumerate(chain_info):\n",
    "    identifier = chain_info_item['identifier']\n",
    "    seq_len = chain_info_item['sequence_length']\n",
    "    \n",
    "    # Get predictions for this chain\n",
    "    pred_contacts = np.array(predictions['predictions'][i])\n",
    "    pred_probabilities = np.array(predictions['probabilities'][i])\n",
    "    confidence_scores = np.array(predictions['confidence_scores'][i])\n",
    "    \n",
    "    # Crop to actual sequence length\n",
    "    if seq_len < 64:\n",
    "        pred_contacts = pred_contacts[:seq_len, :seq_len]\n",
    "        pred_probabilities = pred_probabilities[:seq_len, :seq_len]\n",
    "        confidence_scores = confidence_scores[:seq_len, :seq_len]\n",
    "    else:\n",
    "        pred_contacts = pred_contacts[:seq_len, :seq_len]\n",
    "        pred_probabilities = pred_probabilities[:seq_len, :seq_len]\n",
    "        confidence_scores = confidence_scores[:seq_len, :seq_len]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    total_contacts = np.sum(pred_contacts)\n",
    "    contact_density = total_contacts / (seq_len * (seq_len - 1) / 2) if seq_len > 1 else 0\n",
    "    avg_confidence = np.mean(confidence_scores)\n",
    "    \n",
    "    # Store results\n",
    "    result = {\n",
    "        'identifier': identifier,\n",
    "        'sequence_length': seq_len,\n",
    "        'predicted_contacts': pred_contacts,\n",
    "        'probabilities': pred_probabilities,\n",
    "        'confidence_scores': confidence_scores,\n",
    "        'total_contacts': int(total_contacts),\n",
    "        'contact_density': float(contact_density),\n",
    "        'avg_confidence': float(avg_confidence),\n",
    "        'threshold': predictions['threshold']\n",
    "    }\n",
    "    \n",
    "    results_summary.append(result)\n",
    "    \n",
    "    print(f\"\\nüìä Results for {identifier}:\")\n",
    "    print(f\"   Sequence length: {seq_len}\")\n",
    "    print(f\"   Predicted contacts: {total_contacts:,}\")\n",
    "    print(f\"   Contact density: {contact_density:.4f}\")\n",
    "    print(f\"   Average confidence: {avg_confidence:.4f}\")\n",
    "    print(f\"   Contact map shape: {pred_contacts.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results Analysis and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Visualize Contact Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization of contact predictions\n",
    "n_chains = len(results_summary)\n",
    "if n_chains > 0:\n",
    "    fig, axes = plt.subplots(2, 2*n_chains, figsize=(6*n_chains, 12))\n",
    "    \n",
    "    if n_chains == 1:\n",
    "        axes = axes.reshape(1, -1)  # Handle single chain case\n",
    "    \n",
    "    for i, result in enumerate(results_summary):\n",
    "        identifier = result['identifier']\n",
    "        contacts = result['predicted_contacts']\n",
    "        probabilities = result['probabilities']\n",
    "        confidence = result['confidence_scores']\n",
    "        \n",
    "        # Binary contacts\n",
    "        ax1 = axes[0, 2*i] if n_chains > 1 else axes[0, i]\n",
    "        im1 = ax1.imshow(contacts, cmap='Blues', interpolation='nearest')\n",
    "        ax1.set_title(f'{identifier}\\nBinary Contacts\\n({result[\"total_contacts\"]:,} contacts)')\n",
    "        ax1.set_xlabel('Residue index')\n",
    "        ax1.set_ylabel('Residue index')\n",
    "        plt.colorbar(im1, ax=ax1, fraction=0.046)\n",
    "        \n",
    "        # Probabilities\n",
    "        ax2 = axes[0, 2*i+1] if n_chains > 1 else axes[1, i]\n",
    "        im2 = ax2.imshow(probabilities, cmap='viridis', interpolation='nearest')\n",
    "        ax2.set_title(f'{identifier}\\nContact Probabilities\\n(threshold={result[\"threshold\"]})')\n",
    "        ax2.set_xlabel('Residue index')\n",
    "        ax2.set_ylabel('Residue index')\n",
    "        plt.colorbar(im2, ax=ax2, fraction=0.046)\n",
    "        \n",
    "        # Confidence scores\n",
    "        ax3 = axes[1, 2*i] if n_chains > 1 else axes[2, i]\n",
    "        im3 = ax3.imshow(confidence, cmap='plasma', interpolation='nearest')\n",
    "        ax3.set_title(f'{identifier}\\nConfidence Scores\\n(avg={result[\"avg_confidence\"]:.3f})')\n",
    "        ax3.set_xlabel('Residue index')\n",
    "        ax3.set_ylabel('Residue index')\n",
    "        plt.colorbar(im3, ax=ax3, fraction=0.046)\n",
    "        \n",
    "        # Contact distribution\n",
    "        ax4 = axes[1, 2*i+1] if n_chains > 1 else axes[3, i]\n",
    "        seq_len = result['sequence_length']\n",
    "        \n",
    "        # Calculate contact distribution by sequence separation\n",
    "        separations = range(1, min(seq_len, 50))\n",
    "        contact_rates = []\n",
    "        \n",
    "        for sep in separations:\n",
    "            sep_contacts = 0\n",
    "            total_pairs = 0\n",
    "            for i_pos in range(seq_len - sep):\n",
    "                sep_contacts += contacts[i_pos, i_pos + sep]\n",
    "                total_pairs += 1\n",
    "            contact_rates.append(sep_contacts / total_pairs if total_pairs > 0 else 0)\n",
    "        \n",
    "        ax4.plot(separations, contact_rates, 'b-', linewidth=2)\n",
    "        ax4.set_title(f'{identifier}\\nContact Rate vs Separation')\n",
    "        ax4.set_xlabel('Sequence separation')\n",
    "        ax4.set_ylabel('Contact rate')\n",
    "        ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save figure\n",
    "    output_path = Path(CONFIG['output_dir']) / 'contact_predictions.png'\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"üìä Contact map visualization saved to: {output_path}\")\n",
    "else:\n",
    "    print(\"‚ùå No results to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary statistics table\n",
    "if results_summary:\n",
    "    summary_df = pd.DataFrame([\n",
    "        {\n",
    "            'Chain': result['identifier'],\n",
    "            'Length': result['sequence_length'],\n",
    "            'Contacts': result['total_contacts'],\n",
    "            'Contact Density': f\"{result['contact_density']:.4f}\",\n",
    "            'Avg Confidence': f\"{result['avg_confidence']:.4f}\",\n",
    "            'Max Probability': f\"{np.max(result['probabilities']):.4f}\",\n",
    "            'Threshold': result['threshold']\n",
    "        }\n",
    "        for result in results_summary\n",
    "    ])\n",
    "    \n",
    "    print(\"üìä Prediction Summary:\")\n",
    "    display(summary_df.style.set_caption(\"Contact Prediction Results\"))\n",
    "    \n",
    "    # Save summary to file\n",
    "    summary_path = Path(CONFIG['output_dir']) / 'prediction_summary.csv'\n",
    "    summary_df.to_csv(summary_path, index=False)\n",
    "    print(f\"\\nüíæ Summary saved to: {summary_path}\")\n",
    "else:\n",
    "    print(\"‚ùå No results to summarize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Results and Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Save Complete Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save complete results to JSON\n",
    "if results_summary:\n",
    "    complete_results = {\n",
    "        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'config': CONFIG,\n",
    "        'model_info': {\n",
    "            'model_type': type(predictor).__name__ if predictor else None,\n",
    "            'threshold': predictions.get('threshold', CONFIG['prediction_threshold'])\n",
    "        },\n",
    "        'results': []\n",
    "    }\n",
    "    \n",
    "    # Add individual chain results\n",
    "    for result in results_summary:\n",
    "        complete_results['results'].append({\n",
    "            'identifier': result['identifier'],\n",
    "            'sequence_length': result['sequence_length'],\n",
    "            'total_contacts': result['total_contacts'],\n",
    "            'contact_density': result['contact_density'],\n",
    "            'avg_confidence': result['avg_confidence'],\n",
    "            'predicted_contacts': result['predicted_contacts'].tolist(),\n",
    "            'probabilities': result['probabilities'].tolist(),\n",
    "            'confidence_scores': result['confidence_scores'].tolist()\n",
    "        })\n",
    "    \n",
    "    # Save complete results\n",
    "    complete_results_path = Path(CONFIG['output_dir']) / 'complete_results.json'\n",
    "    with open(complete_results_path, 'w') as f:\n",
    "        json.dump(complete_results, f, indent=2)\n",
    "    \n",
    "    print(f\"üíæ Complete results saved to: {complete_results_path}\")\n",
    "    print(f\"   File size: {complete_results_path.stat().st_size / 1024:.1f} KB\")\n",
    "else:\n",
    "    print(\"‚ùå No results to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 What We Accomplished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéâ ESM2 Contact Prediction Serving - Summary\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\nüìä Processing Results:\")\n",
    "print(f\"   ‚Ä¢ Protein chains analyzed: {len(results_summary)}\")\n",
    "print(f\"   ‚Ä¢ Total contacts predicted: {sum(r['total_contacts'] for r in results_summary):,}\")\n",
    "\n",
    "if results_summary:\n",
    "    avg_density = np.mean([r['contact_density'] for r in results_summary])\n",
    "    avg_confidence = np.mean([r['avg_confidence'] for r in results_summary])\n",
    "    print(f\"   ‚Ä¢ Average contact density: {avg_density:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Average confidence: {avg_confidence:.4f}\")\n",
    "\n",
    "print(f\"\\nüîß Technical Infrastructure:\")\n",
    "print(f\"   ‚Ä¢ Model loading: {'‚úÖ' if predictor else '‚ùå'}\")\n",
    "print(f\"   ‚Ä¢ ESM2 embeddings: {'‚úÖ' if 'embeddings_dict' in locals() else '‚ùå'}\")\n",
    "print(f\"   ‚Ä¢ Contact prediction: {'‚úÖ' if predictions else '‚ùå'}\")\n",
    "print(f\"   ‚Ä¢ Visualization: {'‚úÖ' if 'plt' in locals() else '‚ùå'}\")\n",
    "\n",
    "print(f\"\\nüìÅ Output Files Created:\")\n",
    "output_path = Path(CONFIG['output_dir'])\n",
    "if output_path.exists():\n",
    "    created_files = list(output_path.rglob('*'))\n",
    "    print(f\"   ‚Ä¢ Total files created: {len(created_files)}\")\n",
    "    for file_path in created_files[:10]:  # Show first 10\n",
    "        rel_path = file_path.relative_to(output_path)\n",
    "        size_kb = file_path.stat().st_size / 1024\n",
    "        print(f\"     ‚Ä¢ {rel_path} ({size_kb:.1f} KB)\")\n",
    "    if len(created_files) > 10:\n",
    "        print(f\"     ‚Ä¢ ... and {len(created_files) - 10} more files\")\n",
    "\n",
    "print(f\"\\n‚ú® Successfully completed ESM2 contact prediction serving!\")\n",
    "print(f\"   Model worked with real PDB files and generated contact predictions.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esm2-contact-prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
